{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сегментация магазинов и проверка гипотез (Финальная версия)\n",
    "\n",
    "## Цели исследования\n",
    "1. **Улучшение кластеризации:** Переход от простого K-Means (на сырых данных) к продвинутой сегментации с использованием поведенческих признаков и `RobustScaler` (устойчивость к выбросам).\n",
    "2. **Проверка гипотез:** Тестирование 4-х ключевых бизнес-гипотез от стейкхолдеров (влияние площади, безработицы, праздников и цен на топливо).\n",
    "3. **Прогнозирование:** Построение модели SARIMA для прогноза продаж ключевого сегмента.\n",
    "4. **Бизнес-инсайты:** Формирование стратегий развития."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'myenv (Python 3.14.2)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n myenv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных и создание признаков (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "try:\n",
    "    df = pd.read_csv('df_final.csv', parse_dates=['Date'])\n",
    "    print(f\"Данные загружены. Размер: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Ошибка: Файл df_final.csv не найден. Проверьте путь к файлу.\")\n",
    "\n",
    "# --- Создание профиля магазина ---\n",
    "# Агрегируем временной ряд до уровня \"Магазин\", создавая портрет его поведения\n",
    "\n",
    "profile = df.groupby(['Store']).agg({\n",
    "    'Weekly_Sales': ['mean', 'std', 'sum'],\n",
    "    'IsHoliday': 'mean',          # Доля праздничных недель\n",
    "    'Size': 'first',              # Площадь (константа для магазина)\n",
    "    'Type': 'first',              # Тип магазина\n",
    "    'Unemployment': 'mean',\n",
    "    'Fuel_Price': 'mean',\n",
    "})\n",
    "\n",
    "# Упрощаем названия столбцов\n",
    "profile.columns = ['_'.join(col).strip() for col in profile.columns.values]\n",
    "profile = profile.reset_index()\n",
    "\n",
    "# Переименование для ясности\n",
    "profile.rename(columns={\n",
    "    'Weekly_Sales_mean': 'Avg_Sales',          # Средние продажи\n",
    "    'Weekly_Sales_std': 'Sales_Volatility',    # Волатильность (стандартное отклонение)\n",
    "    'Weekly_Sales_sum': 'Total_Revenue',       # Общая выручка\n",
    "    'Size_first': 'Store_Size',                # Площадь магазина\n",
    "    'Type_first': 'Store_Type'                 # Тип магазина\n",
    "}, inplace=True)\n",
    "\n",
    "# --- Продвинутые поведенческие признаки ---\n",
    "\n",
    "# 1. Holiday Lift (Эффект праздников): Во сколько раз продажи в праздники выше обычных?\n",
    "holiday_sales = df[df['IsHoliday']==True].groupby('Store')['Weekly_Sales'].mean()\n",
    "regular_sales = df[df['IsHoliday']==False].groupby('Store')['Weekly_Sales'].mean()\n",
    "profile['Holiday_Lift'] = (holiday_sales / regular_sales).values\n",
    "\n",
    "# 2. Sales Efficiency (Эффективность площади): Выручка на квадратный фут\n",
    "profile['Sales_Per_SqFt'] = profile['Total_Revenue'] / profile['Store_Size']\n",
    "\n",
    "print(\"Пример профиля магазина (первые 5 строк):\")\n",
    "display(profile.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Улучшенная модель кластеризации\n",
    "Мы используем **RobustScaler** для борьбы с выбросами и фокусируемся на поведенческих метриках (Прирост в праздники, Эффективность, Волатильность), а не просто на объеме продаж."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбор признаков для кластеризации\n",
    "features = ['Avg_Sales', 'Sales_Volatility', 'Store_Size', 'Holiday_Lift', 'Sales_Per_SqFt']\n",
    "X = profile[features].fillna(0)\n",
    "\n",
    "# Robust Scaling (Лучше подходит для финансовых данных с выбросами, чем MinMaxScaler)\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Поиск оптимального K (Метод локтя и Силуэт)\n",
    "wcss = []\n",
    "sil_scores = []\n",
    "K_range = range(2, 10)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    sil_scores.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "\n",
    "# Визуализация метрик выбора кластеров\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax1.set_xlabel('Количество кластеров (k)')\n",
    "ax1.set_ylabel('Inertia (WCSS)', color='tab:blue')\n",
    "ax1.plot(K_range, wcss, 'o-', color='tab:blue', label='Inertia')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Silhouette Score (Силуэт)', color='tab:orange')\n",
    "ax2.plot(K_range, sil_scores, 's--', color='tab:orange', label='Silhouette')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:orange')\n",
    "\n",
    "plt.title('Выбор оптимального количества кластеров')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# Финальная модель (Выбираем K=3)\n",
    "best_k = 3 \n",
    "final_model = KMeans(n_clusters=best_k, random_state=42)\n",
    "profile['Cluster'] = final_model.fit_predict(X_scaled)\n",
    "\n",
    "# --- МЕТРИКИ КАЧЕСТВА КЛАСТЕРИЗАЦИИ ---\n",
    "sil_score = silhouette_score(X_scaled, profile['Cluster'])\n",
    "ch_score = calinski_harabasz_score(X_scaled, profile['Cluster'])\n",
    "db_score = davies_bouldin_score(X_scaled, profile['Cluster'])\n",
    "\n",
    "print(\"Метрики качества кластеризации:\")\n",
    "print(f\"1. Silhouette Score (чем ближе к 1, тем лучше): {sil_score:.4f}\")\n",
    "print(f\"2. Calinski-Harabasz Index (чем выше, тем лучше): {ch_score:.2f}\")\n",
    "print(f\"3. Davies-Bouldin Score (чем ниже, тем лучше): {db_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Профилирование кластеров и Визуализация\n",
    "Анализ характеристик каждого полученного сегмента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средние значения признаков по кластерам\n",
    "cluster_summary = profile.groupby('Cluster')[features].mean()\n",
    "print(\"Профили кластеров (Средние значения):\")\n",
    "display(cluster_summary)\n",
    "\n",
    "# Визуализация 1: PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=profile['Cluster'], palette='viridis', s=100)\n",
    "plt.title('Сегменты магазинов (PCA визуализация)')\n",
    "plt.xlabel('Главная компонента 1')\n",
    "plt.ylabel('Главная компонента 2')\n",
    "plt.legend(title='Кластер')\n",
    "plt.show()\n",
    "\n",
    "# Визуализация 2: Тепловая карта\n",
    "scaler_vis = MinMaxScaler()\n",
    "summary_scaled = pd.DataFrame(scaler_vis.fit_transform(cluster_summary), \n",
    "                              columns=cluster_summary.columns, \n",
    "                              index=cluster_summary.index)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(summary_scaled, annot=True, cmap=\"YlGnBu\", fmt=\".2f\")\n",
    "plt.title('Тепловая карта характеристик кластеров (Нормализовано)')\n",
    "plt.show()\n",
    "\n",
    "# Визуализация 3: Boxplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.boxplot(x='Cluster', y='Avg_Sales', data=profile, palette='Set2', ax=axes[0])\n",
    "axes[0].set_title('Средние продажи')\n",
    "\n",
    "sns.boxplot(x='Cluster', y='Holiday_Lift', data=profile, palette='Set2', ax=axes[1])\n",
    "axes[1].set_title('Прирост в праздники (Lift)')\n",
    "\n",
    "sns.boxplot(x='Cluster', y='Sales_Per_SqFt', data=profile, palette='Set2', ax=axes[2])\n",
    "axes[2].set_title('Эффективность (Продажи на кв.фут)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверка гипотез\n",
    "Теперь мы объединяем данные кластеров с основным набором данных, чтобы протестировать гипотезы на уровне транзакций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение ID кластера с основными данными\n",
    "full_data = df.merge(profile[['Store', 'Cluster']], on='Store', how='left')\n",
    "\n",
    "# Функция для вывода результатов (БЕЗ ЭМОДЗИ)\n",
    "def print_result(h_name, confirmed, details, stats_info=\"\"):\n",
    "    status = \"[+] ПОДТВЕРЖДЕНО\" if confirmed else \"[-] ОТКЛОНЕНО\"\n",
    "    print(f\"\\n{h_name}: {status}\")\n",
    "    print(f\"Детали: {details}\")\n",
    "    if stats_info:\n",
    "        print(f\"Статистика: {stats_info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотеза 1 (Размер магазина)\n",
    "*\"Магазины с площадью более 137000 кв. футов (медиана сегментов 0 и 1) генерируют на 30% больше среднего чека по сравнению с меньшими магазинами\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 137000\n",
    "group_large = full_data[full_data['Size'] > threshold]['Weekly_Sales']\n",
    "group_small = full_data[full_data['Size'] <= threshold]['Weekly_Sales']\n",
    "\n",
    "large_mean = group_large.mean()\n",
    "small_mean = group_small.mean()\n",
    "diff = ((large_mean - small_mean) / small_mean) * 100\n",
    "\n",
    "# T-test\n",
    "t_stat, p_val = stats.ttest_ind(group_large, group_small, equal_var=False)\n",
    "\n",
    "print_result(\n",
    "    \"Гипотеза 1 (Размер)\", \n",
    "    (diff > 30) and (p_val < 0.05), \n",
    "    f\"Крупные (>137k): ${large_mean:.0f}, Мелкие: ${small_mean:.0f}, Разница: +{diff:.1f}%\",\n",
    "    f\"T-statistic={t_stat:.2f}, P-value={p_val:.4f}\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(x=['Мелкие (<=137k)', 'Крупные (>137k)'], y=[small_mean, large_mean], palette='Blues')\n",
    "plt.title('Г1: Средние продажи в зависимости от размера')\n",
    "plt.ylabel('Средние недельные продажи ($)')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'${p.get_height():.0f}', (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', xytext = (0, 9), textcoords = 'offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотеза 2 (Безработица)\n",
    "*\"В сегменте 2 наблюдается более сильная корреляция между уровнем безработицы и объемом продаж (коэффициент > 0.6)\"*\n",
    "\n",
    "*Примечание: Проверяем для нового Кластера 2. Если нумерация изменилась, код проверит все кластеры.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Проверка корреляции для ВСЕХ кластеров:\")\n",
    "h2_confirmed = False\n",
    "target_cluster = 2\n",
    "\n",
    "corrs = {}\n",
    "for c in sorted(full_data['Cluster'].unique()):\n",
    "    subset = full_data[full_data['Cluster'] == c]\n",
    "    # Рассчитываем корреляцию Пирсона и p-value\n",
    "    corr, p_val = stats.pearsonr(subset['Unemployment'], subset['Weekly_Sales'])\n",
    "    corrs[c] = corr\n",
    "    print(f\"Кластер {c} Корреляция: {corr:.4f} (P-value: {p_val:.4f})\")\n",
    "    \n",
    "    if c == target_cluster and abs(corr) > 0.6 and p_val < 0.05:\n",
    "        h2_confirmed = True\n",
    "\n",
    "print_result(\"Гипотеза 2 (Безработица)\", h2_confirmed, f\"Корреляция в Кластере {target_cluster} слишком слабая.\")\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(8, 5))\n",
    "subset_target = full_data[full_data['Cluster'] == target_cluster].sample(min(1000, len(full_data)))\n",
    "sns.regplot(x='Unemployment', y='Weekly_Sales', data=subset_target, \n",
    "            scatter_kws={'alpha':0.3}, line_kws={'color':'red'})\n",
    "plt.title(f'Г2: Влияние безработицы на продажи (Кластер {target_cluster})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотеза 3 (Праздники)\n",
    "*\"Количество праздничных дней значимо влияет на объем продаж только в сегменте 0 (коэффициент регрессии > 0.7)\"*\n",
    "\n",
    "Используем корреляцию Пирсона как прокси для коэффициента \"значимости\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_h3 = []\n",
    "target_cluster = 0\n",
    "\n",
    "for c in sorted(full_data['Cluster'].unique()):\n",
    "    subset = full_data[full_data['Cluster'] == c].copy()\n",
    "    subset['IsHolidayInt'] = subset['IsHoliday'].astype(int)\n",
    "    \n",
    "    X = sm.add_constant(subset[['IsHolidayInt']])\n",
    "    y = subset['Weekly_Sales']\n",
    "    \n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Нам нужен стандартизированный коэффициент (корреляция) для сравнения с порогом 0.7\n",
    "    # или R^2, если речь о силе связи. Используем корреляцию как в условии.\n",
    "    corr = subset['IsHolidayInt'].corr(subset['Weekly_Sales'])\n",
    "    \n",
    "    results_h3.append({\n",
    "        'Кластер': c, \n",
    "        'Корреляция': corr, \n",
    "        'R-squared': model.rsquared,\n",
    "        'P-value': model.pvalues['IsHolidayInt']\n",
    "    })\n",
    "\n",
    "res_h3 = pd.DataFrame(results_h3)\n",
    "display(res_h3)\n",
    "\n",
    "# Проверка: Кластер 0 > 0.7 И остальные < 0.5\n",
    "c0_stats = res_h3[res_h3['Кластер'] == target_cluster].iloc[0]\n",
    "c0_corr = c0_stats['Корреляция']\n",
    "c0_pval = c0_stats['P-value']\n",
    "others_low = res_h3.loc[res_h3['Кластер'] != target_cluster, 'Корреляция'].abs().max() < 0.5\n",
    "\n",
    "print_result(\n",
    "    \"Гипотеза 3 (Влияние праздников)\", \n",
    "    (c0_corr > 0.7) and (c0_pval < 0.05) and others_low, \n",
    "    f\"Корреляция в Кластере {target_cluster}: {c0_corr:.4f}\",\n",
    "    f\"R-squared={c0_stats['R-squared']:.4f}, P-value={c0_pval:.4e}\"\n",
    ")\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x='Кластер', y='Корреляция', data=res_h3, palette='Oranges')\n",
    "plt.axhline(0.7, color='red', linestyle='--', label='Порог значимости (0.7)')\n",
    "plt.title('Г3: Корреляция продаж с праздниками по кластерам')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гипотеза 4 (Чувствительность к цене топлива)\n",
    "*\"При повышении цен на топливо на 0.1$ объем продаж в сегменте 2 снижается на 5% сильнее, чем в других сегментах\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impacts = {}\n",
    "stats_info = []\n",
    "\n",
    "for c in sorted(full_data['Cluster'].unique()):\n",
    "    subset = full_data[full_data['Cluster'] == c]\n",
    "    \n",
    "    X = sm.add_constant(subset[['Fuel_Price']])\n",
    "    y = subset['Weekly_Sales']\n",
    "    \n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # Расчет % падения продаж при росте цены на $0.1\n",
    "    base_sales = subset['Weekly_Sales'].mean()\n",
    "    change_sales = model.params['Fuel_Price'] * 0.1\n",
    "    pct_change = (change_sales / base_sales) * 100\n",
    "    \n",
    "    impacts[c] = pct_change\n",
    "    stats_info.append(f\"Cluster {c}: P-value={model.pvalues['Fuel_Price']:.4f}, R2={model.rsquared:.4f}\")\n",
    "\n",
    "print(\"Влияние роста цены топлива на $0.10:\")\n",
    "for c, val in impacts.items():\n",
    "    print(f\"Кластер {c}: {val:.2f}%\")\n",
    "\n",
    "target_cluster = 2\n",
    "other_avg = np.mean([v for k,v in impacts.items() if k != target_cluster])\n",
    "diff = impacts[target_cluster] - other_avg\n",
    "\n",
    "# Проверка: Падение в Кластере 2 на 5% СИЛЬНЕЕ (т.е. разница < -5%)\n",
    "print_result(\n",
    "    \"Гипотеза 4 (Цена топлива)\", \n",
    "    diff < -5, \n",
    "    f\"Кластер {target_cluster} vs Остальные (Разница): {diff:.2f}%\",\n",
    "    \" | \".join(stats_info)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=list(impacts.keys()), y=list(impacts.values()), palette='Reds')\n",
    "plt.title('Г4: Влияние роста цен на топливо (%)')\n",
    "plt.ylabel('Изменение продаж (%)')\n",
    "plt.axhline(0, color='black', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Прогнозирование продаж (SARIMA)\n",
    "Так как обычная ARIMA плохо справляется с сезонностью розничной торговли, мы используем **SARIMA** для прогноза продаж самого крупного сегмента (Кластер 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка данных для прогнозирования\n",
    "target_c = 0\n",
    "ts_data = full_data[full_data['Cluster'] == target_c].groupby('Date')['Weekly_Sales'].sum()\n",
    "\n",
    "# Ресемплинг по неделям (W)\n",
    "ts_data = ts_data.resample('W').sum()\n",
    "\n",
    "print(f\"Временной ряд для Кластера {target_c} подготовлен. Точек данных: {len(ts_data)}\")\n",
    "\n",
    "# Разделение на обучение и тест (последние 12 недель)\n",
    "train = ts_data.iloc[:-12]\n",
    "test = ts_data.iloc[-12:]\n",
    "\n",
    "# Обучение SARIMA (1, 1, 1) x (1, 1, 1, 52) - 52 недели сезонность\n",
    "print(\"Обучение модели SARIMA (это может занять время)...\")\n",
    "model_sarima = SARIMAX(train, order=(1, 1, 1), seasonal_order=(1, 1, 1, 52))\n",
    "results_sarima = model_sarima.fit(disp=False)\n",
    "\n",
    "# Прогноз\n",
    "forecast = results_sarima.get_forecast(steps=len(test))\n",
    "pred_mean = forecast.predicted_mean\n",
    "conf_int = forecast.conf_int()\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train.index[-52:], train[-52:], label='История (Обучение)')\n",
    "plt.plot(test.index, test, label='Факт (Тест)', color='green')\n",
    "plt.plot(pred_mean.index, pred_mean, label='Прогноз SARIMA', color='red', linestyle='--')\n",
    "plt.fill_between(conf_int.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='pink', alpha=0.3)\n",
    "plt.title(f'Прогноз продаж для Кластера {target_c} (SARIMA)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Метрика качества (MAPE)\n",
    "mape = np.mean(np.abs(pred_mean - test) / test) * 100\n",
    "print(f\"MAPE (Ошибка прогноза): {mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Стратегические рекомендации\n",
    "\n",
    "Автоматическая генерация рекомендаций на основе профилей полученных кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in sorted(profile['Cluster'].unique()):\n",
    "    print(f\"\\n>> Стратегия для Кластера {c}:\")\n",
    "    prof = cluster_summary.loc[c]\n",
    "    \n",
    "    if prof['Avg_Sales'] == cluster_summary['Avg_Sales'].max():\n",
    "        print(\"   * Флагманские магазины (Flagships).\")\n",
    "        print(\"   Действия: Приоритет поставок, премиальные программы лояльности, фокус на удержание.\")\n",
    "    elif prof['Sales_Volatility'] == cluster_summary['Sales_Volatility'].max():\n",
    "        print(\"   ~ Нестабильные магазины (Volatile).\")\n",
    "        print(\"   Действия: Сглаживание спроса через регулярные акции, гибкий график персонала.\")\n",
    "    elif prof['Holiday_Lift'] == cluster_summary['Holiday_Lift'].max():\n",
    "        print(\"   * Праздничные магазины (Holiday Destination).\")\n",
    "        print(\"   Действия: Агрессивный маркетинг в праздники, Pop-up зоны, сезонные товары.\")\n",
    "    else:\n",
    "        print(\"   - Стандартные магазины (Standard).\")\n",
    "        print(\"   Действия: Оптимизация расходов, повышение операционной эффективности.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
